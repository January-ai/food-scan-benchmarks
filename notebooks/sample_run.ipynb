{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f5fa9b",
   "metadata": {},
   "source": [
    "# Food Scan Benchmark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f3b78b",
   "metadata": {},
   "source": [
    "This notebook provides a complete, end-to-end workflow for benchmarking Multimodal Large Language Models (MLLMs) on January's food image dataset (JFID).\n",
    "\n",
    "**The process is as follows:**\n",
    "\n",
    "1.  **Setup:** Install dependencies and configure API keys.\n",
    "2.  **Define Components:** Set up Pydantic schemas, the dataset loader, the model wrapper, and evaluation metrics.\n",
    "3.  **Run Evaluation:** Loop through the dataset, send images to a chosen MLLM, and collect predictions.\n",
    "4.  **Analyze Results:** Calculate metrics and summarize the model's performance.\n",
    "\n",
    "The dataset is automatically downloaded from a public S3 bucket and cached locally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0dd8db",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85827fa",
   "metadata": {},
   "source": [
    "Add your API keys to the environment:\n",
    "\n",
    "```\n",
    "echo OPENAI_API_KEY=\"sk-...\"\n",
    "echo GEMINI_API_KEY=\"...\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374df0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amirhosseinian/January/food-scan-benchmarks/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "%pip install --upgrade litellm boto3 pandas tqdm python-dotenv pydantic tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0107115d",
   "metadata": {},
   "source": [
    "## Core Components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789e0b5",
   "metadata": {},
   "source": [
    "### Schema Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570dc178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Ingredient(BaseModel):\n",
    "    name: str = Field(description=\"Name of the ingredient, e.g., 'scrambled eggs'\")\n",
    "    quantity: float = Field(description=\"Numerical quantity of the ingredient\")\n",
    "    unit: str = Field(description=\"Unit of measurement, e.g., 'cup', 'slice', 'g'\")\n",
    "    calories: float = Field(description=\"Estimated calories for this ingredient\")\n",
    "    carbs: float = Field(\n",
    "        description=\"Estimated grams of carbohydrates for this ingredient\"\n",
    "    )\n",
    "    protein: float = Field(description=\"Estimated grams of protein for this ingredient\")\n",
    "    fat: float = Field(description=\"Estimated grams of fat for this ingredient\")\n",
    "\n",
    "\n",
    "class TotalMacros(BaseModel):\n",
    "    calories: float = Field(description=\"Total estimated calories for the entire meal\")\n",
    "    carbs: float = Field(\n",
    "        description=\"Total estimated grams of carbohydrates for the entire meal\"\n",
    "    )\n",
    "    protein: float = Field(\n",
    "        description=\"Total estimated grams of protein for the entire meal\"\n",
    "    )\n",
    "    fat: float = Field(description=\"Total estimated grams of fat for the entire meal\")\n",
    "\n",
    "\n",
    "class FoodAnalysis(BaseModel):\n",
    "    meal_name: str = Field(\n",
    "        description=\"A descriptive name for the meal, e.g., 'Breakfast Platter'\"\n",
    "    )\n",
    "    ingredients: List[Ingredient] = Field(\n",
    "        description=\"A list of all identified ingredients and their nutritional information\"\n",
    "    )\n",
    "    total_macros: TotalMacros = Field(\n",
    "        description=\"The sum of macros for all ingredients\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3985a2ca",
   "metadata": {},
   "source": [
    "### Model Costs Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eab56aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_COSTS = {\n",
    "    \"gpt-4.1\": {\"input\": 2.00, \"output\": 8.00},\n",
    "    \"gpt-4o\": {\"input\": 2.50, \"output\": 10.00},\n",
    "    \"gpt-4o-mini\": {\"input\": 0.15, \"output\": 0.60},\n",
    "    \"gemini/gemini-2.5-flash-preview-05-20\": {\"input\": 0.15, \"output\": 0.60},\n",
    "    \"gemini/gemini-2.5-pro-preview-06-05\": {\"input\": 1.25, \"output\": 10.00},\n",
    "}\n",
    "\n",
    "\n",
    "def calculate_cost(model_name: str, input_tokens: int, output_tokens: int) -> float:\n",
    "    \"\"\"Calculate the cost for a model based on token usage.\"\"\"\n",
    "    if model_name not in MODEL_COSTS:\n",
    "        return 0.0\n",
    "\n",
    "    costs = MODEL_COSTS[model_name]\n",
    "    input_cost = (input_tokens / 1_000_000) * costs[\"input\"]\n",
    "    output_cost = (output_tokens / 1_000_000) * costs[\"output\"]\n",
    "    return round(input_cost + output_cost, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eab9d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def img2b64(path: Path) -> str:\n",
    "    \"\"\"Converts an image file to a base64 encoded string for API calls.\"\"\"\n",
    "    encoded = base64.b64encode(path.read_bytes()).decode()\n",
    "    return f\"data:image/jpeg;base64,{encoded}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4438935",
   "metadata": {},
   "source": [
    "### Dataset Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe960109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "import tarfile\n",
    "\n",
    "\n",
    "class FoodScanDataset:\n",
    "    \"\"\"Handles downloading, caching, and loading the food dataset.\"\"\"\n",
    "\n",
    "    _S3_BUCKET = \"january-food-image-dataset-public\"\n",
    "    _S3_KEY = \"food-scan-benchmark-dataset.tar.gz\"\n",
    "\n",
    "    def __init__(self, root: Path):\n",
    "        self.root = root.expanduser()\n",
    "        self.img_dir = self.root / \"food-scan-benchmark-dataset\" / \"fsb_images\"\n",
    "        self.csv_path = (\n",
    "            self.root / \"food-scan-benchmark-dataset\" / \"food_scan_bench_v1.csv\"\n",
    "        )\n",
    "\n",
    "        if not self.csv_path.exists():\n",
    "            self._download_and_extract()\n",
    "\n",
    "        self.df = pd.read_csv(self.csv_path)\n",
    "\n",
    "    def _download_and_extract(self):\n",
    "        print(f\"Dataset not found in {self.root}. Downloading from S3...\")\n",
    "        self.root.mkdir(parents=True, exist_ok=True)\n",
    "        local_archive = self.root / \"fsb.tar.gz\"\n",
    "\n",
    "        s3 = boto3.client(\n",
    "            \"s3\",\n",
    "            config=Config(signature_version=UNSIGNED),\n",
    "        )\n",
    "        with open(local_archive, \"wb\") as f:\n",
    "            s3.download_fileobj(self._S3_BUCKET, self._S3_KEY, f)\n",
    "\n",
    "        print(\"Download complete. Extracting...\")\n",
    "        with tarfile.open(local_archive) as tar:\n",
    "            tar.extractall(path=self.root)\n",
    "        local_archive.unlink()\n",
    "        print(\"Extraction complete.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.img_dir / row.image_filename\n",
    "\n",
    "        try:\n",
    "            ingredients = ast.literal_eval(row.ingredients_list)\n",
    "        except (ValueError, SyntaxError):\n",
    "            ingredients = []\n",
    "\n",
    "        return {\n",
    "            \"image_id\": row.image_id,\n",
    "            \"image_path\": img_path,\n",
    "            \"gt\": {\n",
    "                \"meal_name\": row.meal_name,\n",
    "                \"ingredients\": ingredients,\n",
    "                \"macros\": {\n",
    "                    \"calories\": row.total_calories,\n",
    "                    \"carbs\": row.total_carbs,\n",
    "                    \"protein\": row.total_protein,\n",
    "                    \"fat\": row.total_fat,\n",
    "                },\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0756e7",
   "metadata": {},
   "source": [
    "### Model Wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0490690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "from litellm.exceptions import APIError\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "\n",
    "class LiteModel:\n",
    "    \"\"\"A robust wrapper around any LiteLLM-supported vision model.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str, **litellm_kwargs):\n",
    "        self.model_name = model_name\n",
    "        self.kwargs = litellm_kwargs\n",
    "\n",
    "    async def analyse(self, img_path: Path) -> Optional[dict]:\n",
    "        \"\"\"Analyzes an image and returns a structured dict with cost info, or None on failure.\"\"\"\n",
    "        b64_img = img2b64(img_path)\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert nutritionist. Analyze the food image and provide a detailed breakdown in the requested JSON format.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Identify the food, its ingredients with quantities and macros, and the total macros.\",\n",
    "                    },\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": b64_img}},\n",
    "                ],\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            resp = await litellm.acompletion(\n",
    "                model=self.model_name,\n",
    "                messages=messages,\n",
    "                response_format=FoodAnalysis,\n",
    "                temperature=0.0,\n",
    "                **self.kwargs,\n",
    "            )\n",
    "            raw = resp.choices[0].message.content.strip()\n",
    "            data = json.loads(raw)\n",
    "\n",
    "            usage = resp.usage\n",
    "            input_tokens = usage.prompt_tokens if usage else 0\n",
    "            output_tokens = usage.completion_tokens if usage else 0\n",
    "            cost = calculate_cost(self.model_name, input_tokens, output_tokens)\n",
    "\n",
    "            result = FoodAnalysis(**data).model_dump()\n",
    "            result[\"cost_usd\"] = cost\n",
    "\n",
    "            return result\n",
    "\n",
    "        except APIError as e:\n",
    "            print(f\"API Error for {img_path.name}: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred for {img_path.name}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642c13d",
   "metadata": {},
   "source": [
    "### Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6beb16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def ingredients_f1(gt, pred) -> float:\n",
    "    \"\"\"\n",
    "    F-score on ingredient names (case-insensitive).\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(gt, str):\n",
    "        try:\n",
    "            gt = ast.literal_eval(gt)\n",
    "        except Exception:\n",
    "            gt = [gt]\n",
    "    if isinstance(pred, str):\n",
    "        try:\n",
    "            pred = ast.literal_eval(pred)\n",
    "        except Exception:\n",
    "            pred = [pred]\n",
    "\n",
    "    def _name(x):\n",
    "        if isinstance(x, dict):\n",
    "            x = x.get(\"name\", \"\")\n",
    "        return str(x).lower().strip()\n",
    "\n",
    "    g_names = {_name(x) for x in gt if _name(x)}\n",
    "    p_names = {_name(x) for x in pred if _name(x)}\n",
    "\n",
    "    if not g_names and not p_names:\n",
    "        return 1.0\n",
    "    if not g_names or not p_names:\n",
    "        return 0.0\n",
    "\n",
    "    tp = len(g_names & p_names)\n",
    "    if tp == 0:\n",
    "        return 0.0\n",
    "    precision = tp / len(p_names)\n",
    "    recall = tp / len(g_names)\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "\n",
    "def macro_mae(gt_mac: dict, pred_mac: dict) -> float:\n",
    "    \"\"\"Calculates Mean Absolute Error over the four main macros.\"\"\"\n",
    "    keys = [\"calories\", \"carbs\", \"protein\", \"fat\"]\n",
    "    errors = [abs(gt_mac[k] - pred_mac.get(k, 0)) for k in keys]\n",
    "    return float(np.mean(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7885e9f",
   "metadata": {},
   "source": [
    "## Evaluation Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f880e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import asyncio\n",
    "import time\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "async def _process_sample(\n",
    "    idx: int,\n",
    "    ds: FoodScanDataset,\n",
    "    llm: LiteModel,\n",
    "    model_name: str,\n",
    ") -> dict:\n",
    "    start_time = time.time()\n",
    "    sample = ds[idx]\n",
    "    pred = await llm.analyse(sample[\"image_path\"])\n",
    "    end_time = time.time()\n",
    "    gt = sample[\"gt\"]\n",
    "\n",
    "    item = {\n",
    "        \"image_id\": sample[\"image_id\"],\n",
    "        \"model\": model_name,\n",
    "        \"response_time_seconds\": round(end_time - start_time, 2),\n",
    "    }\n",
    "\n",
    "    if pred is None:\n",
    "        item.update(\n",
    "            {\"f1_ing\": 0.0, \"mae_mac\": None, \"error\": \"failed\", \"cost_usd\": 0.0}\n",
    "        )\n",
    "    else:\n",
    "        f1 = ingredients_f1(gt[\"ingredients\"], pred.get(\"ingredients\", []))\n",
    "        mae = macro_mae(gt[\"macros\"], pred.get(\"total_macros\", {}))\n",
    "        item.update(\n",
    "            {\n",
    "                \"f1_ing\": f1,\n",
    "                \"mae_mac\": mae,\n",
    "                \"error\": None,\n",
    "                \"cost_usd\": pred.get(\"cost_usd\", 0.0),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return item\n",
    "\n",
    "\n",
    "async def _run_model_evaluation(\n",
    "    model_name: str,\n",
    "    ds: FoodScanDataset,\n",
    "    n: int,\n",
    "    max_concurrent: int,\n",
    "    position: int,\n",
    ") -> List[dict]:\n",
    "    llm = LiteModel(model_name)\n",
    "    sem = asyncio.Semaphore(max_concurrent)\n",
    "\n",
    "    pbar = tqdm(\n",
    "        total=n,\n",
    "        desc=model_name.ljust(20),\n",
    "        position=position,\n",
    "        leave=True,\n",
    "        dynamic_ncols=True,\n",
    "        colour=\"cyan\",\n",
    "        bar_format=\"{desc}│{bar}│ {n:>2}/{total}\",\n",
    "    )\n",
    "\n",
    "    async def _worker(i: int):\n",
    "        async with sem:\n",
    "            result = await _process_sample(i, ds, llm, model_name)\n",
    "            pbar.update(1)\n",
    "            return result\n",
    "\n",
    "    results = await asyncio.gather(*(_worker(i) for i in range(n)))\n",
    "    pbar.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "async def run_evaluation(\n",
    "    models: Union[str, List[str]],\n",
    "    cache_dir: Path,\n",
    "    max_items: Optional[int] = None,\n",
    "    max_concurrent: int = 5,\n",
    ") -> List[dict]:\n",
    "    if isinstance(models, str):\n",
    "        models = [models]\n",
    "\n",
    "    ds = FoodScanDataset(cache_dir)\n",
    "    n = min(max_items, len(ds)) if max_items else len(ds)\n",
    "\n",
    "    model_tasks = [\n",
    "        _run_model_evaluation(model_name, ds, n, max_concurrent, position=i)\n",
    "        for i, model_name in enumerate(models)\n",
    "    ]\n",
    "\n",
    "    nested_results = await asyncio.gather(*model_tasks)\n",
    "    return [item for sub in nested_results for item in sub]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde80caf",
   "metadata": {},
   "source": [
    "## Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa733757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a983269e98af4ce9b59f7b0ff4fbca32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gpt-4.1             │          │  0/3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f7ed28328b402e863c697d354dbdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gpt-4o              │          │  0/3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d367a257741640c28785d024f8ea2a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gemini/gemini-2.5-flash-preview-05-20│          │  0/3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>model</th>\n",
       "      <th>response_time_seconds</th>\n",
       "      <th>f1_ing</th>\n",
       "      <th>mae_mac</th>\n",
       "      <th>error</th>\n",
       "      <th>cost_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fsb_00000</td>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>95.525</td>\n",
       "      <td>None</td>\n",
       "      <td>0.006572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fsb_00001</td>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.650</td>\n",
       "      <td>None</td>\n",
       "      <td>0.006380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fsb_00002</td>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>10.32</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>84.200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.007572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fsb_00000</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>9.56</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>127.650</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fsb_00001</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>12.675</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fsb_00002</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>11.78</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>23.925</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fsb_00000</td>\n",
       "      <td>gemini/gemini-2.5-flash-preview-05-20</td>\n",
       "      <td>11.09</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>158.350</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fsb_00001</td>\n",
       "      <td>gemini/gemini-2.5-flash-preview-05-20</td>\n",
       "      <td>8.58</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>17.650</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fsb_00002</td>\n",
       "      <td>gemini/gemini-2.5-flash-preview-05-20</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.425</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id                                  model  response_time_seconds  \\\n",
       "0  fsb_00000                                gpt-4.1                  14.09   \n",
       "1  fsb_00001                                gpt-4.1                  14.57   \n",
       "2  fsb_00002                                gpt-4.1                  10.32   \n",
       "3  fsb_00000                                 gpt-4o                   9.56   \n",
       "4  fsb_00001                                 gpt-4o                   6.47   \n",
       "5  fsb_00002                                 gpt-4o                  11.78   \n",
       "6  fsb_00000  gemini/gemini-2.5-flash-preview-05-20                  11.09   \n",
       "7  fsb_00001  gemini/gemini-2.5-flash-preview-05-20                   8.58   \n",
       "8  fsb_00002  gemini/gemini-2.5-flash-preview-05-20                   5.15   \n",
       "\n",
       "     f1_ing  mae_mac error  cost_usd  \n",
       "0  0.333333   95.525  None  0.006572  \n",
       "1  0.000000   26.650  None  0.006380  \n",
       "2  0.285714   84.200  None  0.007572  \n",
       "3  0.666667  127.650  None  0.005915  \n",
       "4  0.666667   12.675  None  0.005215  \n",
       "5  0.400000   23.925  None  0.005785  \n",
       "6  0.461538  158.350  None  0.001160  \n",
       "7  0.666667   17.650  None  0.000818  \n",
       "8  0.000000   30.425  None  0.000359  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Single model\n",
    "MODELS = \"gpt-4o\"\n",
    "# Multiple models\n",
    "# MODELS = [\"gpt-4o\", \"gpt-4o-mini\"]\n",
    "MODELS = [\n",
    "    \"gpt-4.1\",\n",
    "    \"gpt-4o\",\n",
    "    \"gemini/gemini-2.5-flash-preview-05-20\",\n",
    "    # \"gemini/gemini-2.5-pro-preview-06-05\",\n",
    "]\n",
    "# MODELS = [\"gemini/gemini-2.5-flash-preview-05-20\", \"gemini/gemini-2.5-pro-preview-06-05\"]\n",
    "\n",
    "MAX_IMGS = 3\n",
    "CACHE_DIR = Path(\".cache/food_scan_bench\")\n",
    "\n",
    "# Run with multiple models\n",
    "results = await run_evaluation(\n",
    "    models=MODELS,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    max_items=MAX_IMGS,\n",
    "    max_concurrent=10,\n",
    ")\n",
    "\n",
    "pd.DataFrame(results).head(9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
